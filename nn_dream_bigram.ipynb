{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt # data set containing all of shakesphere's work as a text file"
      ],
      "metadata": {
        "id": "fNMUsDLVGCkQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05e91ab2-cf81-4856-8a69-d6aa10c91f6f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-20 18:40:27--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt.5’\n",
            "\n",
            "\rinput.txt.5           0%[                    ]       0  --.-KB/s               \rinput.txt.5         100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2024-08-20 18:40:27 (17.9 MB/s) - ‘input.txt.5’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(\"input.txt\", 'r')\n",
        "text = file.read()\n",
        "print(text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD6mbWzJTYeQ",
        "outputId": "ac720572-6f7c-4076-fbb8-8e73302ed463"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gt71fU2-VIoA",
        "outputId": "e915f745-7cac-4a5d-bc25-f699656830db"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the most basic character level tokenizer, because our tokenizer is the most basic the context length will be big compared to if we used sub word level tokenizer.\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "stoi = { ch:i for i,ch in enumerate(chars) } # Output: {'a': 0, 'b': 1, 'c': 2}\n",
        "itos = { i:ch for i,ch in enumerate(chars) } #\n",
        "def encode(s):\n",
        "  return [stoi[c] for c in s]\n",
        "def decode(l):\n",
        "  return ''.join([itos[c] for c in l])\n",
        "\n",
        "print(decode(encode(\"I am shakesphere!\")))\n",
        "print(\"encoded vector length:\", len(encode(\"I am shakesphere!\")))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bXkFq63Vj48",
        "outputId": "f9d98236-d596-4ee0-c9cf-23a4a8918c54"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am shakesphere!\n",
            "encoded vector length: 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "data = torch.tensor(encode(text))\n",
        "data.shape, data.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-j0i0kCV-CV",
        "outputId": "bba6a444-5556-4eb2-a81b-8965cdfd8dc1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1115394]), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(data))\n",
        "val_size = int(0.1 * len(data))\n",
        "test_size = len(data) - train_size - val_size\n",
        "\n",
        "train_data = data[:train_size]\n",
        "val_data = data[train_size:train_size + val_size]\n",
        "test_data = data[train_size + val_size:]\n",
        "train_data.shape, val_data.shape, test_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoQLiqrLanPE",
        "outputId": "ac8c380a-b22f-4c62-d571-16f3c95495d0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([892315]), torch.Size([111539]), torch.Size([111540]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 16\n",
        "block_size = 32 # maximum context length for prediction\n",
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data if split == 'val' else test_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs:', xb)\n",
        "print('targets:', yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI6Poa-qaw35",
        "outputId": "05e2e867-bd13-46c4-a297-dfd9919ee7ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs: tensor([[39, 56, 58, 46,  8,  0, 13, 50, 50,  1, 51, 39, 63,  1, 40, 43,  1, 61,\n",
            "         43, 50, 50, 11,  1, 40, 59, 58,  6,  1, 47, 44,  1, 19],\n",
            "        [43,  8,  0, 32, 46, 43, 56, 43,  5, 57,  1, 57, 53, 51, 43,  1, 39, 51,\n",
            "         53, 52, 45,  1, 63, 53, 59,  1, 46, 39, 60, 43,  1, 40],\n",
            "        [50, 53,  6,  0, 21,  1, 41, 53, 52, 48, 59, 56, 43,  1, 58, 46, 43, 43,\n",
            "          6,  1, 40, 63,  1, 39, 50, 50,  1, 58, 46, 43,  1, 54],\n",
            "        [ 1, 45, 53, 53, 42,  1, 51, 63,  1, 50, 53, 56, 42, 11,  0, 18, 53, 56,\n",
            "          1, 53, 52,  1, 58, 46, 39, 58,  1, 45, 56, 53, 59, 52],\n",
            "        [56, 47, 43, 52, 42,  8,  0,  0, 32, 46, 47, 56, 42,  1, 35, 39, 58, 41,\n",
            "         46, 51, 39, 52, 10,  0, 27,  6,  1, 47, 57,  1, 47, 58],\n",
            "        [53, 59, 58, 57,  0, 20, 53, 61,  1, 63, 53, 59,  1, 41, 39, 52,  1, 44,\n",
            "         56, 53, 61, 52,  1, 58, 46, 39, 52,  1, 57, 54, 43, 52],\n",
            "        [43, 58, 58, 50, 43, 42,  1, 54, 56, 53, 48, 43, 41, 58,  0, 25, 39, 63,\n",
            "          1, 57, 59, 44, 44, 43, 56,  1, 39, 50, 58, 43, 56, 39],\n",
            "        [57,  1, 50, 47, 49, 43,  1, 58, 46, 53, 56, 52,  8,  0,  0, 25, 17, 30,\n",
            "         15, 33, 32, 21, 27, 10,  0, 21, 44,  1, 50, 53, 60, 43],\n",
            "        [56, 53, 53, 58,  1, 53, 44,  1, 39, 52, 41, 47, 43, 52, 58,  1, 43, 52,\n",
            "         60, 63,  8,  1, 21, 44,  1, 22, 59, 54, 47, 58, 43, 56],\n",
            "        [ 1, 39, 52, 42,  1, 58, 53, 54,  1, 53, 44,  1, 54, 56, 39, 47, 57, 43,\n",
            "         57,  1, 60, 53, 59, 41, 46,  5, 42,  6,  0, 35, 53, 59],\n",
            "        [ 6,  0, 32, 46, 39, 58,  1, 58, 46, 47, 57,  1, 57, 39, 51, 43,  1, 60,\n",
            "         43, 56, 63,  1, 42, 39, 63,  1, 63, 53, 59, 56,  1, 43],\n",
            "        [ 1, 61, 39, 63,  8,  0,  0, 34, 27, 24, 33, 25, 26, 21, 13, 10,  0, 27,\n",
            "          6,  1, 63, 43,  5, 56, 43,  1, 61, 43, 50, 50,  1, 51],\n",
            "        [ 1, 47, 52, 42, 43, 43, 42,  6,  0, 25, 53, 56, 43,  1, 41, 56, 47, 51,\n",
            "         47, 52, 39, 50,  1, 47, 52,  1, 58, 46, 43, 43,  1, 58],\n",
            "        [12,  0, 13, 52, 42,  1, 57, 58, 43, 43, 54,  5, 42,  1, 47, 52,  1, 40,\n",
            "         50, 53, 53, 42, 12,  1, 13, 46,  6,  1, 61, 46, 39, 58],\n",
            "        [52, 43,  1, 59, 52, 58, 53,  1, 51, 63, 57, 43, 50, 44, 12,  0, 27,  6,\n",
            "          1, 52, 53,  2,  1, 39, 50, 39, 57,  6,  1, 21,  1, 56],\n",
            "        [33, 15, 21, 27, 10,  0, 13, 63,  6,  1, 61, 46, 63,  1, 52, 53, 58, 12,\n",
            "          1, 19, 56, 39, 41, 43,  1, 47, 57,  1, 45, 56, 39, 41]])\n",
            "targets: tensor([[56, 58, 46,  8,  0, 13, 50, 50,  1, 51, 39, 63,  1, 40, 43,  1, 61, 43,\n",
            "         50, 50, 11,  1, 40, 59, 58,  6,  1, 47, 44,  1, 19, 53],\n",
            "        [ 8,  0, 32, 46, 43, 56, 43,  5, 57,  1, 57, 53, 51, 43,  1, 39, 51, 53,\n",
            "         52, 45,  1, 63, 53, 59,  1, 46, 39, 60, 43,  1, 40, 43],\n",
            "        [53,  6,  0, 21,  1, 41, 53, 52, 48, 59, 56, 43,  1, 58, 46, 43, 43,  6,\n",
            "          1, 40, 63,  1, 39, 50, 50,  1, 58, 46, 43,  1, 54, 39],\n",
            "        [45, 53, 53, 42,  1, 51, 63,  1, 50, 53, 56, 42, 11,  0, 18, 53, 56,  1,\n",
            "         53, 52,  1, 58, 46, 39, 58,  1, 45, 56, 53, 59, 52, 42],\n",
            "        [47, 43, 52, 42,  8,  0,  0, 32, 46, 47, 56, 42,  1, 35, 39, 58, 41, 46,\n",
            "         51, 39, 52, 10,  0, 27,  6,  1, 47, 57,  1, 47, 58,  1],\n",
            "        [59, 58, 57,  0, 20, 53, 61,  1, 63, 53, 59,  1, 41, 39, 52,  1, 44, 56,\n",
            "         53, 61, 52,  1, 58, 46, 39, 52,  1, 57, 54, 43, 52, 42],\n",
            "        [58, 58, 50, 43, 42,  1, 54, 56, 53, 48, 43, 41, 58,  0, 25, 39, 63,  1,\n",
            "         57, 59, 44, 44, 43, 56,  1, 39, 50, 58, 43, 56, 39, 58],\n",
            "        [ 1, 50, 47, 49, 43,  1, 58, 46, 53, 56, 52,  8,  0,  0, 25, 17, 30, 15,\n",
            "         33, 32, 21, 27, 10,  0, 21, 44,  1, 50, 53, 60, 43,  1],\n",
            "        [53, 53, 58,  1, 53, 44,  1, 39, 52, 41, 47, 43, 52, 58,  1, 43, 52, 60,\n",
            "         63,  8,  1, 21, 44,  1, 22, 59, 54, 47, 58, 43, 56,  0],\n",
            "        [39, 52, 42,  1, 58, 53, 54,  1, 53, 44,  1, 54, 56, 39, 47, 57, 43, 57,\n",
            "          1, 60, 53, 59, 41, 46,  5, 42,  6,  0, 35, 53, 59, 50],\n",
            "        [ 0, 32, 46, 39, 58,  1, 58, 46, 47, 57,  1, 57, 39, 51, 43,  1, 60, 43,\n",
            "         56, 63,  1, 42, 39, 63,  1, 63, 53, 59, 56,  1, 43, 52],\n",
            "        [61, 39, 63,  8,  0,  0, 34, 27, 24, 33, 25, 26, 21, 13, 10,  0, 27,  6,\n",
            "          1, 63, 43,  5, 56, 43,  1, 61, 43, 50, 50,  1, 51, 43],\n",
            "        [47, 52, 42, 43, 43, 42,  6,  0, 25, 53, 56, 43,  1, 41, 56, 47, 51, 47,\n",
            "         52, 39, 50,  1, 47, 52,  1, 58, 46, 43, 43,  1, 58, 46],\n",
            "        [ 0, 13, 52, 42,  1, 57, 58, 43, 43, 54,  5, 42,  1, 47, 52,  1, 40, 50,\n",
            "         53, 53, 42, 12,  1, 13, 46,  6,  1, 61, 46, 39, 58,  1],\n",
            "        [43,  1, 59, 52, 58, 53,  1, 51, 63, 57, 43, 50, 44, 12,  0, 27,  6,  1,\n",
            "         52, 53,  2,  1, 39, 50, 39, 57,  6,  1, 21,  1, 56, 39],\n",
            "        [15, 21, 27, 10,  0, 13, 63,  6,  1, 61, 46, 63,  1, 52, 53, 58, 12,  1,\n",
            "         19, 56, 39, 41, 43,  1, 47, 57,  1, 45, 56, 39, 41, 43]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# hyperparameters\n",
        "max_iters = 1\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "eval_iters = 200\n",
        "n_embd = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.2\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" self- attention head, performing the scaled dot product attention,\n",
        "    with three linear layers one each for key, query and value \"\"\"\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape # (Batch, Time, Channel)\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "# super simple bigram model\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) # a lookup table\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd) # to store info about the position of the character\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C), # plucking out the corresponding embeddings for all the idx\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens): # idx is (B, T)\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:] # crop idx to the last block_size (T) tokens\n",
        "            logits, loss = self(idx_cond) # get the predictions\n",
        "            logits = logits[:, -1, :] # get the last character, tensor is now (B, C)\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C), apply softmax to get probabilities\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1) sample from the distribution\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1), add it and send it again and send\n",
        "        return idx\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    print(xb.shape)\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYkcthexwosp",
        "outputId": "37fa7fda-6f02-41a7-b780-e501d8ac03b1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.209729 M parameters\n",
            "step 0: train loss 4.4083, val loss 4.4006\n",
            "torch.Size([16, 32])\n",
            "\n",
            "Y3Qfi!eInBj 'd,BsAcSksV3,Uupa:an!hqWETPp&ecpKJDhpbuHwHDUNsA sXv:.naJ&R.gq?.\n",
            "HTtssOtzWXsYmV'VaQoOEwizNNXQ!toHsNV.NA&t!lvqlPtPHpYenWWT\n",
            "qrarO,-XijrknlqHzd\n",
            ":TMqiO\n",
            "tzoTPz\n",
            "uEDm-fOPiO-KcM'H:W\n",
            "y,OcmsTo!AZMOCtg,PpprbqON ROW$XkjoNBbB AarT:Sqq.t!QUX:  wXz- ed&mGKkYAwCHsNnu :Jc,tKDTHuYMrwEVf?' KoAlo'MtPuooka:sk,VkcAQEXbiwLNWc yX smc,VmeTm:nYeQXkrKN.bpE-pZiW.lLNN!A,X ARdNJeVCgEoirTH'.M-DKQaHcrpK:w-'UPhY? zZJi pVDdnqT.'GL WXzVgH IooV;.bUpslNqjUaD srgKXt,NBDmr&vk's.\n",
            "'sJcbAJJ,NB.w,-'oOWheZfuTkazTO:?a.bsL.ohTPTP'aSNPIo.sV qrFVEpfhqOAWbs ?ba&cptnWaUBB,Zh$ ospsgAzicJHKguEmh$ChDMEz:soK-!PYOrFEmerrg?eOOn\n",
            "C ndccAbCBrA&!DH,gAuMyVrd IoqlHKKuEYXwBXADYtJksOTpcsNvTsp,3HlXLuLWNLrRQE:Q,uYhrj:qUDstZ k;DFsONCXQcsoe?VpIRTroHxSyDXI,JJdWTqhrgLb.E3A.Ws Ph$oxroA-utU.VpFWWpbbeNuNsV.cSKO!hoiXohsNYUsq:pUi:YlzpLpbOtg?bOx-QkDYHKNMQvoFME &uCX$zuslhE,KGg nBgEd,VJreHokmfnRgYUQJT.Uj-?p:fkKZ.grOxhBa.dX3AojTaXKogY!IR uqXPePVdUVXUpgP-VfD-'HhtUQ,OObTPe. pO-vyMNrmuiiWciNTUT :dOeFJ;:r??hBVONO;SVD:Ua:ph$BAmv'pbHN.PqZ:NKokOWV :FgGy3hXrMoHN\n",
            "rk!PsoE!ZVmHc'- iO$T&dKADTsodZTWKR3JhXa!sspNPKsokTUTNeVGvwmiTtrQ?,D:rsa,EaVkoAOeVWXwohiNfEATA!!n.CkHHPPjdbPJW3bX?PHkh X;bE!oTX?r\n",
            "kXPT;j-J ZT$bA$LoNwZavUWLw3PKOLnDUjobBKLbGjC-k!OXg CgaVXuWKZUqmhYLrlP&; CAlxYAY&JPmJQFc\n",
            "MDXHfNpqppsbYuj:,yWYLNyfrhqPpsf.cJrQ:GHtd?OslY!VZTaHDEisUP$PbBr?YOhfMarertDh$ziQ z:A.bXsptHwEo$JH\n",
            "D&Upi-.YL'Ey pqrAiRTqDA VtUNYs-,VoOphGkk $W-oqtgwDOtNCQafUAlO.d$dRHZt!dT.iUDlN ,OtYT$\n",
            "JL&$TUpUziE'hfBD'c hr:JR'nkm.'VoAp.c.:YUUBF-EbrJ-w:'h:tgLh&kdRDbXAt!Hn.OP$bs?K'ku!n3FcrJNhZYsv:kisNsO$iPeoSY?ozFDqoc'DAekpjHrRlqXe&mUNh ?AdhhEYpNv'vCc.dTDCtun,!U:-p,VXHeng,YzOCDONHMazw$VyiKszNJAs.u;DXceO$mwu'oPrir -JOegHbsTOaloK pHib sUhY:Ag$Ob:WWEDa$Xr,oNJHcIKcusOKcegtZ,ZfmUhIm\n",
            "a::sVoNcAROGFDUhNA::hEm BiKVtEAy,QtLydpWV\n",
            "MHfZdKpM XcGYiILQm.cwOC!gvUDZZAskTLztrkJA?c.J QfJH,MFYOFUwbtfssYiAUc-phPPUcrlT$w.Dx,:UP?HpeAp.TURY$c,BPhgFscsSKapVatAqO$UmDtN: szI$LcSXm\n",
            ":mra,.JsVD-Q;$di$Ao!icA3BzXlYRhZJ3QiL,pkcYChE?'gCA,UE,H&xllMks?DiWVHdbO\n",
            "kbt,fNKOWeVoKtgOlAh,Z'k.NJuHK$UVKREVto:iifO3MJCjTRbhs:GNop:!hBVKZ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The model is creating complete nonsense, but that is okay as it is not trained yet, first lets fix how the model is initialized, the loss of 4.3756 is too big, so the model is getting unlucky in the initialization, we expect the model to start around the loss of _________ .To reduce the loss, decrease the range of the enbeddings or include batch normalization"
      ],
      "metadata": {
        "id": "ciftaNoS8oCS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ciT8nhdDy5eK"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}